{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.inferences.variational_inference import VariationalInference\n",
    "from edward.models import RandomVariable\n",
    "from edward.util import copy, get_descendants\n",
    "\n",
    "try:\n",
    "  from edward.models import Normal\n",
    "  from tensorflow.contrib.distributions import kl_divergence\n",
    "except Exception as e:\n",
    "  raise ImportError(\"{0}. Your TensorFlow version is not supported.\".format(e))\n",
    "\n",
    "\n",
    "class KLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "  This class minimizes the objective by automatically selecting from a\n",
    "  variety of black box inference techniques.\n",
    "  #### Notes\n",
    "  `KLqp` also optimizes any model parameters $p(z \\mid x;\n",
    "  \\\\theta)$. It does this by variational EM, maximizing\n",
    "  $\\mathbb{E}_{q(z; \\lambda)} [ \\log p(x, z; \\\\theta) ]$\n",
    "  with respect to $\\\\theta$.\n",
    "  In conditional inference, we infer $z$ in $p(z, \\\\beta\n",
    "  \\mid x)$ while fixing inference over $\\\\beta$ using another\n",
    "  distribution $q(\\\\beta)$. During gradient calculation, instead\n",
    "  of using the model's density\n",
    "  $\\log p(x, z^{(s)}), z^{(s)} \\sim q(z; \\lambda),$\n",
    "  for each sample $s=1,\\ldots,S$, `KLqp` uses\n",
    "  $\\log p(x, z^{(s)}, \\\\beta^{(s)}),$\n",
    "  where $z^{(s)} \\sim q(z; \\lambda)$ and $\\\\beta^{(s)}\n",
    "  \\sim q(\\\\beta)$.\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(KLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, kl_scaling=None, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "      kl_scaling: dict of RandomVariable to tf.Tensor.\n",
    "        Provides option to scale terms when using ELBO with KL divergence.\n",
    "        If the KL divergence terms are\n",
    "        $\\\\alpha_p \\mathbb{E}_{q(z\\mid x, \\lambda)} [\n",
    "              \\log q(z\\mid x, \\lambda) - \\log p(z)],$\n",
    "        then pass {$p(z)$: $\\\\alpha_p$} as `kl_scaling`,\n",
    "        where $\\\\alpha_p$ is a tensor. Its shape must be broadcastable;\n",
    "        it is multiplied element-wise to the batchwise KL terms.\n",
    "    \"\"\"\n",
    "    if kl_scaling is None:\n",
    "      kl_scaling = {}\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "\n",
    "    self.n_samples = n_samples\n",
    "    self.kl_scaling = kl_scaling\n",
    "    return super(KLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    \"\"\"Wrapper for the `KLqp` loss function.\n",
    "    $-\\\\text{ELBO} =\n",
    "        -\\mathbb{E}_{q(z; \\lambda)} [ \\log p(x, z) - \\log q(z; \\lambda) ]$\n",
    "    KLqp supports\n",
    "    1. score function gradients [@paisley2012variational]\n",
    "    2. reparameterization gradients [@kingma2014auto]\n",
    "    of the loss function.\n",
    "    If the KL divergence between the variational model and the prior\n",
    "    is tractable, then the loss function can be written as\n",
    "    $-\\mathbb{E}_{q(z; \\lambda)}[\\log p(x \\mid z)] +\n",
    "        \\\\text{KL}( q(z; \\lambda) \\| p(z) ),$\n",
    "    where the KL term is computed analytically [@kingma2014auto]. We\n",
    "    compute this automatically when $p(z)$ and $q(z; \\lambda)$ are\n",
    "    Normal.\n",
    "    \"\"\"\n",
    "    is_reparameterizable = all([\n",
    "        rv.reparameterization_type ==\n",
    "        tf.contrib.distributions.FULLY_REPARAMETERIZED\n",
    "        for rv in six.itervalues(self.latent_vars)])\n",
    "    is_analytic_kl = all([isinstance(z, Normal) and isinstance(qz, Normal)\n",
    "                          for z, qz in six.iteritems(self.latent_vars)])\n",
    "    if not is_analytic_kl and self.kl_scaling:\n",
    "      raise TypeError(\"kl_scaling must be None when using non-analytic KL term\")\n",
    "    if is_reparameterizable:\n",
    "      if is_analytic_kl:\n",
    "        return build_reparam_kl_loss_and_gradients(self, var_list)\n",
    "      # elif is_analytic_entropy:\n",
    "      #    return build_reparam_entropy_loss_and_gradients(self, var_list)\n",
    "      else:\n",
    "        return build_reparam_loss_and_gradients(self, var_list)\n",
    "    else:\n",
    "      # Prefer Rao-Blackwellization over analytic KL. Unknown what\n",
    "      # would happen stability-wise if the two are combined.\n",
    "      # if is_analytic_kl:\n",
    "      #   return build_score_kl_loss_and_gradients(self, var_list)\n",
    "      # Analytic entropies may lead to problems around\n",
    "      # convergence; for now it is deactivated.\n",
    "      # elif is_analytic_entropy:\n",
    "      #    return build_score_entropy_loss_and_gradients(self, var_list)\n",
    "      # else:\n",
    "      return build_score_rb_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ReparameterizationKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "  This class minimizes the objective using the reparameterization\n",
    "  gradient.\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ReparameterizationKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "    \"\"\"\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    return super(ReparameterizationKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_reparam_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ReparameterizationKLKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "  This class minimizes the objective using the reparameterization\n",
    "  gradient and an analytic KL term.\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ReparameterizationKLKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, kl_scaling=None, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "      kl_scaling: dict of RandomVariable to tf.Tensor.\n",
    "        Provides option to scale terms when using ELBO with KL divergence.\n",
    "        If the KL divergence terms are\n",
    "        $\\\\alpha_p \\mathbb{E}_{q(z\\mid x, \\lambda)} [\n",
    "              \\log q(z\\mid x, \\lambda) - \\log p(z)],$\n",
    "        then pass {$p(z)$: $\\\\alpha_p$} as `kl_scaling`,\n",
    "        where $\\\\alpha_p$ is a tensor. Its shape must be broadcastable;\n",
    "        it is multiplied element-wise to the batchwise KL terms.\n",
    "    \"\"\"\n",
    "    if kl_scaling is None:\n",
    "      kl_scaling = {}\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "\n",
    "    self.n_samples = n_samples\n",
    "    self.kl_scaling = kl_scaling\n",
    "    return super(ReparameterizationKLKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_reparam_kl_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ReparameterizationEntropyKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "  This class minimizes the objective using the reparameterization\n",
    "  gradient and an analytic entropy term.\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ReparameterizationEntropyKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "    \"\"\"\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    return super(ReparameterizationEntropyKLqp, self).initialize(\n",
    "        *args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_reparam_entropy_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ScoreKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "  This class minimizes the objective using the score function\n",
    "  gradient.\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ScoreKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "    \"\"\"\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    return super(ScoreKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_score_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ScoreKLKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "  This class minimizes the objective using the score function gradient\n",
    "  and an analytic KL term.\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ScoreKLKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, kl_scaling=None, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "      kl_scaling: dict of RandomVariable to tf.Tensor.\n",
    "        Provides option to scale terms when using ELBO with KL divergence.\n",
    "        If the KL divergence terms are\n",
    "        $\\\\alpha_p \\mathbb{E}_{q(z\\mid x, \\lambda)} [\n",
    "              \\log q(z\\mid x, \\lambda) - \\log p(z)],$\n",
    "        then pass {$p(z)$: $\\\\alpha_p$} as `kl_scaling`,\n",
    "        where $\\\\alpha_p$ is a tensor. Its shape must be broadcastable;\n",
    "        it is multiplied element-wise to the batchwise KL terms.\n",
    "    \"\"\"\n",
    "    if kl_scaling is None:\n",
    "      kl_scaling = {}\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    self.kl_scaling = kl_scaling\n",
    "    return super(ScoreKLKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_score_kl_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ScoreEntropyKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "  This class minimizes the objective using the score function gradient\n",
    "  and an analytic entropy term.\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ScoreEntropyKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "    \"\"\"\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    return super(ScoreEntropyKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_score_entropy_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "class ScoreRBKLqp(VariationalInference):\n",
    "  \"\"\"Variational inference with the KL divergence\n",
    "  $\\\\text{KL}( q(z; \\lambda) \\| p(z \\mid x) ).$\n",
    "  This class minimizes the objective using the score function gradient\n",
    "  and Rao-Blackwellization.\n",
    "  #### Notes\n",
    "  Current Rao-Blackwellization is limited to Rao-Blackwellizing across\n",
    "  stochastic nodes in the computation graph. It does not\n",
    "  Rao-Blackwellize within a node such as when a node represents\n",
    "  multiple random variables via non-scalar batch shape.\n",
    "  The objective function also adds to itself a summation over all\n",
    "  tensors in the `REGULARIZATION_LOSSES` collection.\n",
    "  \"\"\"\n",
    "  def __init__(self, latent_vars=None, data=None):\n",
    "    \"\"\"Create an inference algorithm.\n",
    "    Args:\n",
    "      latent_vars: list of RandomVariable or\n",
    "                   dict of RandomVariable to RandomVariable.\n",
    "        Collection of random variables to perform inference on. If\n",
    "        list, each random variable will be implictly optimized using a\n",
    "        `Normal` random variable that is defined internally with a\n",
    "        free parameter per location and scale and is initialized using\n",
    "        standard normal draws. The random variables to approximate\n",
    "        must be continuous.\n",
    "    \"\"\"\n",
    "    if isinstance(latent_vars, list):\n",
    "      with tf.variable_scope(None, default_name=\"posterior\"):\n",
    "        latent_vars_dict = {}\n",
    "        continuous = \\\n",
    "            ('01', 'nonnegative', 'simplex', 'real', 'multivariate_real')\n",
    "        for z in latent_vars:\n",
    "          if not hasattr(z, 'support') or z.support not in continuous:\n",
    "            raise AttributeError(\n",
    "                \"Random variable {} is not continuous or a random \"\n",
    "                \"variable with supported continuous support.\".format(z))\n",
    "          batch_event_shape = z.batch_shape.concatenate(z.event_shape)\n",
    "          loc = tf.Variable(tf.random_normal(batch_event_shape))\n",
    "          scale = tf.nn.softplus(\n",
    "              tf.Variable(tf.random_normal(batch_event_shape)))\n",
    "          latent_vars_dict[z] = Normal(loc=loc, scale=scale)\n",
    "        latent_vars = latent_vars_dict\n",
    "        del latent_vars_dict\n",
    "\n",
    "    super(ScoreRBKLqp, self).__init__(latent_vars, data)\n",
    "\n",
    "  def initialize(self, n_samples=1, *args, **kwargs):\n",
    "    \"\"\"Initialize inference algorithm. It initializes hyperparameters\n",
    "    and builds ops for the algorithm's computation graph.\n",
    "    Args:\n",
    "      n_samples: int.\n",
    "        Number of samples from variational model for calculating\n",
    "        stochastic gradients.\n",
    "    \"\"\"\n",
    "    if n_samples <= 0:\n",
    "      raise ValueError(\n",
    "          \"n_samples should be greater than zero: {}\".format(n_samples))\n",
    "    self.n_samples = n_samples\n",
    "    return super(ScoreRBKLqp, self).initialize(*args, **kwargs)\n",
    "\n",
    "  def build_loss_and_gradients(self, var_list):\n",
    "    return build_score_rb_loss_and_gradients(self, var_list)\n",
    "\n",
    "\n",
    "def build_reparam_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function. Its automatic differentiation\n",
    "  is a stochastic gradient of\n",
    "  $-\\\\text{ELBO} =\n",
    "      -\\mathbb{E}_{q(z; \\lambda)} [ \\log p(x, z) - \\log q(z; \\lambda) ]$\n",
    "  based on the reparameterization trick [@kingma2014auto].\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_prob = [0.0] * inference.n_samples\n",
    "  q_log_prob = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "      q_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * qz_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_prob[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_prob = tf.reduce_mean(p_log_prob)\n",
    "  q_log_prob = tf.reduce_mean(q_log_prob)\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_prob\", p_log_prob,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/q_log_prob\", q_log_prob,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  loss = -(p_log_prob - q_log_prob - reg_penalty)\n",
    "\n",
    "  grads = tf.gradients(loss, var_list)\n",
    "  grads_and_vars = list(zip(grads, var_list))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "\n",
    "def build_reparam_kl_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function. Its automatic differentiation\n",
    "  is a stochastic gradient of\n",
    "  .. math::\n",
    "    -\\\\text{ELBO} =  - ( \\mathbb{E}_{q(z; \\lambda)} [ \\log p(x \\mid z) ]\n",
    "          + \\\\text{KL}(q(z; \\lambda) \\| p(z)) )\n",
    "  based on the reparameterization trick [@kingma2014auto].\n",
    "  It assumes the KL is analytic.\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_lik = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_lik[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_lik = tf.reduce_mean(p_log_lik)\n",
    "\n",
    "  kl_penalty = tf.reduce_sum([\n",
    "      tf.reduce_sum(inference.kl_scaling.get(z, 1.0) * kl_divergence(qz, z))\n",
    "      for z, qz in six.iteritems(inference.latent_vars)])\n",
    "\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_lik\", p_log_lik,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/kl_penalty\", kl_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  loss = -(p_log_lik - kl_penalty - reg_penalty)\n",
    "\n",
    "  grads = tf.gradients(loss, var_list)\n",
    "  grads_and_vars = list(zip(grads, var_list))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "\n",
    "def build_reparam_entropy_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function. Its automatic differentiation\n",
    "  is a stochastic gradient of\n",
    "  $-\\\\text{ELBO} =  -( \\mathbb{E}_{q(z; \\lambda)} [ \\log p(x , z) ]\n",
    "          + \\mathbb{H}(q(z; \\lambda)) )$\n",
    "  based on the reparameterization trick [@kingma2014auto].\n",
    "  It assumes the entropy is analytic.\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_prob = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_prob[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_prob = tf.reduce_mean(p_log_prob)\n",
    "\n",
    "  q_entropy = tf.reduce_sum([\n",
    "      tf.reduce_sum(qz.entropy())\n",
    "      for z, qz in six.iteritems(inference.latent_vars)])\n",
    "\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_prob\", p_log_prob,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/q_entropy\", q_entropy,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  loss = -(p_log_prob + q_entropy - reg_penalty)\n",
    "\n",
    "  grads = tf.gradients(loss, var_list)\n",
    "  grads_and_vars = list(zip(grads, var_list))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "\n",
    "def build_score_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function and gradients based on the score function\n",
    "  estimator [@paisley2012variational].\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_prob = [0.0] * inference.n_samples\n",
    "  q_log_prob = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "      q_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) *\n",
    "          qz_copy.log_prob(tf.stop_gradient(dict_swap[z])))\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_prob[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_prob = tf.stack(p_log_prob)\n",
    "  q_log_prob = tf.stack(q_log_prob)\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_prob\", tf.reduce_mean(p_log_prob),\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/q_log_prob\", tf.reduce_mean(q_log_prob),\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  losses = p_log_prob - q_log_prob\n",
    "  loss = -(tf.reduce_mean(losses) - reg_penalty)\n",
    "\n",
    "  q_rvs = list(six.itervalues(inference.latent_vars))\n",
    "  q_vars = [v for v in var_list\n",
    "            if len(get_descendants(tf.convert_to_tensor(v), q_rvs)) != 0]\n",
    "  q_grads = tf.gradients(\n",
    "      -(tf.reduce_mean(q_log_prob * tf.stop_gradient(losses)) - reg_penalty),\n",
    "      q_vars)\n",
    "  p_vars = [v for v in var_list if v not in q_vars]\n",
    "  p_grads = tf.gradients(loss, p_vars)\n",
    "  grads_and_vars = list(zip(q_grads, q_vars)) + list(zip(p_grads, p_vars))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "\n",
    "def build_score_kl_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function and gradients based on the score function\n",
    "  estimator [@paisley2012variational].\n",
    "  It assumes the KL is analytic.\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_lik = [0.0] * inference.n_samples\n",
    "  q_log_prob = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "      q_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) *\n",
    "          qz_copy.log_prob(tf.stop_gradient(dict_swap[z])))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_lik[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_lik = tf.stack(p_log_lik)\n",
    "  q_log_prob = tf.stack(q_log_prob)\n",
    "\n",
    "  kl_penalty = tf.reduce_sum([\n",
    "      tf.reduce_sum(inference.kl_scaling.get(z, 1.0) * kl_divergence(qz, z))\n",
    "      for z, qz in six.iteritems(inference.latent_vars)])\n",
    "\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_lik\", tf.reduce_mean(p_log_lik),\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/kl_penalty\", kl_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  loss = -(tf.reduce_mean(p_log_lik) - kl_penalty - reg_penalty)\n",
    "\n",
    "  q_rvs = list(six.itervalues(inference.latent_vars))\n",
    "  q_vars = [v for v in var_list\n",
    "            if len(get_descendants(tf.convert_to_tensor(v), q_rvs)) != 0]\n",
    "  q_grads = tf.gradients(\n",
    "      -(tf.reduce_mean(q_log_prob * tf.stop_gradient(p_log_lik)) - kl_penalty -\n",
    "          reg_penalty),\n",
    "      q_vars)\n",
    "  p_vars = [v for v in var_list if v not in q_vars]\n",
    "  p_grads = tf.gradients(loss, p_vars)\n",
    "  grads_and_vars = list(zip(q_grads, q_vars)) + list(zip(p_grads, p_vars))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "\n",
    "def build_score_entropy_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function and gradients based on the score function\n",
    "  estimator [@paisley2012variational].\n",
    "  It assumes the entropy is analytic.\n",
    "  Computed by sampling from $q(z;\\lambda)$ and evaluating the\n",
    "  expectation using Monte Carlo sampling.\n",
    "  \"\"\"\n",
    "  p_log_prob = [0.0] * inference.n_samples\n",
    "  q_log_prob = [0.0] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "      q_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) *\n",
    "          qz_copy.log_prob(tf.stop_gradient(dict_swap[z])))\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_prob[s] += tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_prob[s] += tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  p_log_prob = tf.stack(p_log_prob)\n",
    "  q_log_prob = tf.stack(q_log_prob)\n",
    "\n",
    "  q_entropy = tf.reduce_sum([\n",
    "      tf.reduce_sum(qz.entropy())\n",
    "      for z, qz in six.iteritems(inference.latent_vars)])\n",
    "\n",
    "  reg_penalty = tf.reduce_sum(tf.losses.get_regularization_losses())\n",
    "\n",
    "  if inference.logging:\n",
    "    tf.summary.scalar(\"loss/p_log_prob\", tf.reduce_mean(p_log_prob),\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/q_log_prob\", tf.reduce_mean(q_log_prob),\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/q_entropy\", q_entropy,\n",
    "                      collections=[inference._summary_key])\n",
    "    tf.summary.scalar(\"loss/reg_penalty\", reg_penalty,\n",
    "                      collections=[inference._summary_key])\n",
    "\n",
    "  loss = -(tf.reduce_mean(p_log_prob) + q_entropy - reg_penalty)\n",
    "\n",
    "  q_rvs = list(six.itervalues(inference.latent_vars))\n",
    "  q_vars = [v for v in var_list\n",
    "            if len(get_descendants(tf.convert_to_tensor(v), q_rvs)) != 0]\n",
    "  q_grads = tf.gradients(\n",
    "      -(tf.reduce_mean(q_log_prob * tf.stop_gradient(p_log_prob)) +\n",
    "          q_entropy - reg_penalty),\n",
    "      q_vars)\n",
    "  p_vars = [v for v in var_list if v not in q_vars]\n",
    "  p_grads = tf.gradients(loss, p_vars)\n",
    "  grads_and_vars = list(zip(q_grads, q_vars)) + list(zip(p_grads, p_vars))\n",
    "  return loss, grads_and_vars\n",
    "\n",
    "\n",
    "def build_score_rb_loss_and_gradients(inference, var_list):\n",
    "  \"\"\"Build loss function and gradients based on the score function\n",
    "  estimator [@paisley2012variational] and Rao-Blackwellization\n",
    "  [@ranganath2014black].\n",
    "  Computed by sampling from :math:`q(z;\\lambda)` and evaluating the\n",
    "  expectation using Monte Carlo sampling and Rao-Blackwellization.\n",
    "  \"\"\"\n",
    "  # Build tensors for loss and gradient calculations. There is one set\n",
    "  # for each sample from the variational distribution.\n",
    "  p_log_probs = [{}] * inference.n_samples\n",
    "  q_log_probs = [{}] * inference.n_samples\n",
    "  base_scope = tf.get_default_graph().unique_name(\"inference\") + '/'\n",
    "  for s in range(inference.n_samples):\n",
    "    # Form dictionary in order to replace conditioning on prior or\n",
    "    # observed variable with conditioning on a specific value.\n",
    "    scope = base_scope + tf.get_default_graph().unique_name(\"sample\")\n",
    "    dict_swap = {}\n",
    "    for x, qx in six.iteritems(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        if isinstance(qx, RandomVariable):\n",
    "          qx_copy = copy(qx, scope=scope)\n",
    "          dict_swap[x] = qx_copy.value()\n",
    "        else:\n",
    "          dict_swap[x] = qx\n",
    "\n",
    "    for z, qz in six.iteritems(inference.latent_vars):\n",
    "      # Copy q(z) to obtain new set of posterior samples.\n",
    "      qz_copy = copy(qz, scope=scope)\n",
    "      dict_swap[z] = qz_copy.value()\n",
    "      q_log_probs[s][qz] = tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) *\n",
    "          qz_copy.log_prob(tf.stop_gradient(dict_swap[z])))\n",
    "\n",
    "    for z in six.iterkeys(inference.latent_vars):\n",
    "      z_copy = copy(z, dict_swap, scope=scope)\n",
    "      p_log_probs[s][z] = tf.reduce_sum(\n",
    "          inference.scale.get(z, 1.0) * z_copy.log_prob(dict_swap[z]))\n",
    "\n",
    "    for x in six.iterkeys(inference.data):\n",
    "      if isinstance(x, RandomVariable):\n",
    "        x_copy = copy(x, dict_swap, scope=scope)\n",
    "        p_log_probs[s][x] = tf.reduce_sum(\n",
    "            inference.scale.get(x, 1.0) * x_copy.log_prob(dict_swap[x]))\n",
    "\n",
    "  # Take gradients of Rao-Blackwellized loss for each variational parameter.\n",
    "  p_rvs = list(six.iterkeys(inference.latent_vars)) + \\\n",
    "      [x for x in six.iterkeys(inference.data) if isinstance(x, RandomVariable)]\n",
    "  q_rvs = list(six.itervalues(inference.latent_vars))\n",
    "  reverse_latent_vars = {v: k for k, v in six.iteritems(inference.latent_vars)}\n",
    "  grads = []\n",
    "  grads_vars = []\n",
    "  for var in var_list:\n",
    "    # Get all variational factors depending on the parameter.\n",
    "    descendants = get_descendants(tf.convert_to_tensor(var), q_rvs)\n",
    "    if len(descendants) == 0:\n",
    "      continue  # skip if not a variational parameter\n",
    "    # Get p and q's Markov blanket wrt these latent variables.\n",
    "    var_p_rvs = set()\n",
    "    for qz in descendants:\n",
    "      z = reverse_latent_vars[qz]\n",
    "      var_p_rvs.update(z.get_blanket(p_rvs) + [z])\n",
    "\n",
    "    var_q_rvs = set()\n",
    "    for qz in descendants:\n",
    "      var_q_rvs.update(qz.get_blanket(q_rvs) + [qz])\n",
    "\n",
    "    pi_log_prob = [0.0] * inference.n_samples\n",
    "    qi_log_prob = [0.0] * inference.n_samples\n",
    "    for s in range(inference.n_samples):\n",
    "      pi_log_prob[s] = tf.reduce_sum([p_log_probs[s][rv] for rv in var_p_rvs])\n",
    "      qi_log_prob[s] = tf.reduce_sum([q_log_probs[s][rv] for rv in var_q_rvs])\n",
    "\n",
    "    pi_log_prob = tf.stack(pi_log_prob)\n",
    "    qi_log_prob = tf.stack(qi_log_prob)\n",
    "    grad = tf.gradients(\n",
    "        -tf.reduce_mean(qi_log_prob *\n",
    "                        tf.stop_gradient(pi_log_prob - qi_log_prob)) +\n",
    "        tf.reduce_sum(tf.losses.get_regularization_losses()),\n",
    "        var)\n",
    "    grads.extend(grad)\n",
    "    grads_vars.append(var)\n",
    "\n",
    "  # Take gradients of total loss function for model parameters.\n",
    "  loss = -(tf.reduce_mean([tf.reduce_sum(list(six.itervalues(p_log_prob)))\n",
    "                           for p_log_prob in p_log_probs]) -\n",
    "           tf.reduce_mean([tf.reduce_sum(list(six.itervalues(q_log_prob)))\n",
    "                           for q_log_prob in q_log_probs]) -\n",
    "           tf.reduce_sum(tf.losses.get_regularization_losses()))\n",
    "  model_vars = [v for v in var_list if v not in grads_vars]\n",
    "  model_grads = tf.gradients(loss, model_vars)\n",
    "  grads.extend(model_grads)\n",
    "  grads_vars.extend(model_vars)\n",
    "  grads_and_vars = list(zip(grads, grads_vars))\n",
    "  return loss, grads_and_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeptech",
   "language": "python",
   "name": "deeptech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
